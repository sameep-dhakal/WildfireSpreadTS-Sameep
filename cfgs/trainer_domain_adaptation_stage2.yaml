# ======================================================
# Trainer configuration for Stage 2 (Weight Estimator)
# ======================================================

accelerator: gpu
strategy: auto
devices: 1
num_nodes: 1
precision: 32-true

logger:
  class_path: pytorch_lightning.loggers.wandb.WandbLogger
  init_args:
    project: domain_adaptation_res50
    log_model: true

# ======================================================
# Checkpoint callback â€” monitors val_loss_D instead of val_avg_precision
# ======================================================
callbacks:
  - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
    init_args:
      monitor: val_loss_D          # discriminator validation loss
      mode: min                    # lower is better
      save_top_k: 1                # keep only best one
      save_last: true              # keep last as fallback
      filename: "{epoch}-{val_loss_D:.4f}"
      auto_insert_metric_name: false

# ======================================================
# Basic trainer settings
# ======================================================
fast_dev_run: false
max_epochs: 50                     # usually enough for D to converge
min_epochs: 1
max_steps: -1
min_steps: -1
check_val_every_n_epoch: 1         # run val loop every epoch
val_check_interval: null
num_sanity_val_steps: 0            # skip sanity checks since we validate manually
log_every_n_steps: 25              # W&B logging frequency

enable_checkpointing: true
enable_progress_bar: true
enable_model_summary: true
accumulate_grad_batches: 1

deterministic: warn
benchmark: true

inference_mode: true
use_distributed_sampler: true
detect_anomaly: false
barebones: false
sync_batchnorm: false
reload_dataloaders_every_n_epochs: 0

# ======================================================
# Default output directory
# Will be overridden by sweep to /develop/results/stage2_foldX
# ======================================================
default_root_dir: /develop/results/
