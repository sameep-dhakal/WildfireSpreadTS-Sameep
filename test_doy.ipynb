{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf454a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.FireSpreadDataset import FireSpreadDataset\n",
    "\n",
    "dataset_with_doy = FireSpreadDataset(\n",
    "    data_dir=\"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/Data/WIldfireSpreadTS_HDF5\",\n",
    "    included_fire_years=[2019],\n",
    "    n_leading_observations=5,\n",
    "    crop_side_length=128,\n",
    "    load_from_hdf5=True,\n",
    "    is_train=False,\n",
    "    remove_duplicate_features=False,\n",
    "    stats_years=(2018, 2020),\n",
    "    return_doy=True  # âœ… get day-of-year\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7992fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.FireSpreadDataset import FireSpreadDataset\n",
    "\n",
    "dataset_without_doy = FireSpreadDataset(\n",
    "    data_dir=\"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/Data/WIldfireSpreadTS_HDF5\",\n",
    "    included_fire_years=[2019],\n",
    "    n_leading_observations=5,\n",
    "    crop_side_length=128,\n",
    "    load_from_hdf5=True,\n",
    "    is_train=False,\n",
    "    remove_duplicate_features=False,\n",
    "    stats_years=(2018, 2020),\n",
    "    return_doy=False # âœ… get day-of-year\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7c1e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample with DOY: tensor([66., 67., 68., 69., 70.])\n",
      "Shape without DOY: torch.Size([5, 40, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Dataset with DOY\n",
    "x1, y1, doys1 = dataset_with_doy[0]\n",
    "print(\"Sample with DOY:\", doys1)\n",
    "\n",
    "# Dataset without DOY just gives x,y\n",
    "x2, y2 = dataset_without_doy[0]\n",
    "print(\"Shape without DOY:\", x2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6459ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/sameeps/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:04<00:00, 11.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "ðŸš€ Mean absolute diff between DOY vs no DOY: 1.067734\n"
     ]
    }
   ],
   "source": [
    "from models.SMPTempModel import SMPTempModel\n",
    "\n",
    "model_with_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x1.shape[1], \n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",  # âœ… required!\n",
    "    use_doy=True\n",
    ")\n",
    "\n",
    "\n",
    "model_no_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x1.shape[1],\n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",  # âœ…\n",
    "    use_doy=False\n",
    ")\n",
    "\n",
    "\n",
    "# (B, T, C, H, W) inputs\n",
    "x1_batched = x1.unsqueeze(0)\n",
    "doys1_batched = doys1.unsqueeze(0)\n",
    "\n",
    "# Run through both models\n",
    "out_with_doy = model_with_doy(x1_batched, doys1_batched)\n",
    "out_no_doy = model_no_doy(x1_batched, doys1_batched)\n",
    "\n",
    "diff = torch.mean(torch.abs(out_with_doy - out_no_doy)).item()\n",
    "print(f\"ðŸš€ Mean absolute diff between DOY vs no DOY: {diff:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a13a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded sample shapes:\n",
      "    x:    torch.Size([5, 40, 128, 128])  # (T, C, H, W)\n",
      "    y:    torch.Size([128, 128])  # (H, W)\n",
      "    doys: torch.Size([5])  # (T,) \n",
      "  doys values: tensor([33., 34., 35., 36., 37.])\n",
      "\n",
      "ðŸš€ Ready to pass through model:\n",
      "    x1_batched:    torch.Size([1, 5, 40, 128, 128])\n",
      "    doys1_batched: torch.Size([1, 5])\n",
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "\n",
      ">>> Running forward with DOY...\n",
      "âœ… Output shape (with DOY): torch.Size([1, 1, 128, 128])\n",
      "\n",
      ">>> Running forward without DOY...\n",
      "âœ… Output shape (without DOY): torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataloader.FireSpreadDataset import FireSpreadDataset\n",
    "from models.SMPTempModel import SMPTempModel\n",
    "\n",
    "# âœ… Load your dataset\n",
    "dataset_with_doy = FireSpreadDataset(\n",
    "    data_dir=\"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/Data/WIldfireSpreadTS_HDF5\",\n",
    "    included_fire_years=[2021],\n",
    "    n_leading_observations=5,\n",
    "    crop_side_length=128,\n",
    "    load_from_hdf5=True,\n",
    "    is_train=False,\n",
    "    remove_duplicate_features=False,\n",
    "    stats_years=[2018, 2020],\n",
    "    return_doy=True\n",
    ")\n",
    "\n",
    "# âœ… Grab one sample\n",
    "x1, y1, doys1 = dataset_with_doy[0]\n",
    "print(f\"âœ… Loaded sample shapes:\\n\"\n",
    "      f\"    x:    {x1.shape}  # (T, C, H, W)\\n\"\n",
    "      f\"    y:    {y1.shape}  # (H, W)\\n\"\n",
    "      f\"    doys: {doys1.shape}  # (T,) \\n \"\n",
    "      f\" doys values: {doys1}\"\n",
    "      )\n",
    "\n",
    "\n",
    "# âœ… Add batch dimension\n",
    "x1_batched = x1.unsqueeze(0)       # (1, T, C, H, W)\n",
    "doys1_batched = doys1.unsqueeze(0) # (1, T)\n",
    "\n",
    "# âœ… Make sure these are float tensors\n",
    "x1_batched = x1_batched.float()\n",
    "doys1_batched = doys1_batched.float()\n",
    "\n",
    "print(f\"\\nðŸš€ Ready to pass through model:\\n\"\n",
    "      f\"    x1_batched:    {x1_batched.shape}\\n\"\n",
    "      f\"    doys1_batched: {doys1_batched.shape}\")\n",
    "\n",
    "# âœ… Instantiate the model\n",
    "model_with_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x1.shape[1],  # C\n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",\n",
    "    use_doy=True\n",
    ")\n",
    "\n",
    "model_no_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x1.shape[1],  # C\n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",\n",
    "    use_doy=False\n",
    ")\n",
    "\n",
    "# âœ… Forward pass with DOY\n",
    "print(\"\\n>>> Running forward with DOY...\")\n",
    "out_with_doy = model_with_doy.forward(x1_batched, doys1_batched)\n",
    "print(f\"âœ… Output shape (with DOY): {out_with_doy.shape}\")\n",
    "\n",
    "# âœ… Forward pass without DOY\n",
    "print(\"\\n>>> Running forward without DOY...\")\n",
    "out_no_doy = model_no_doy.forward(x1_batched, doys1_batched)\n",
    "print(f\"âœ… Output shape (without DOY): {out_no_doy.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a4072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Loaded sample WITHOUT DOY:\n",
      "    x shape: torch.Size([5, 40, 128, 128])  # (T, C, H, W)\n",
      "    y shape: torch.Size([128, 128])  # (H, W)\n",
      "\n",
      "ðŸš€ x2_batched shape (ready for model): torch.Size([1, 5, 40, 128, 128])\n",
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "\n",
      ">>> Running forward on model with use_doy=True but doy=None:\n",
      "âœ… Output shape (auto dummy DOY created inside forward): torch.Size([1, 1, 128, 128])\n",
      "Loaded resnet18 with imagenet weights + LTAE\n",
      "\n",
      ">>> Running forward on model with use_doy=False (also creates dummy internally):\n",
      "âœ… Output shape (use_doy=False so dummy DOY used anyway): torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataloader.FireSpreadDataset import FireSpreadDataset\n",
    "from models.SMPTempModel import SMPTempModel\n",
    "\n",
    "# âœ… Load dataset that does NOT return DOY\n",
    "dataset_no_doy = FireSpreadDataset(\n",
    "    data_dir=\"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/Data/WIldfireSpreadTS_HDF5\",\n",
    "    included_fire_years=[2019],\n",
    "    n_leading_observations=5,\n",
    "    crop_side_length=128,\n",
    "    load_from_hdf5=True,\n",
    "    is_train=False,\n",
    "    remove_duplicate_features=False,\n",
    "    stats_years=[2018, 2020],\n",
    "    return_doy=False  # <---- no doy returned\n",
    ")\n",
    "\n",
    "# âœ… Grab a single sample\n",
    "x2, y2 = dataset_no_doy[0]\n",
    "print(f\"\\nâœ… Loaded sample WITHOUT DOY:\\n\"\n",
    "      f\"    x shape: {x2.shape}  # (T, C, H, W)\\n\"\n",
    "      f\"    y shape: {y2.shape}  # (H, W)\")\n",
    "\n",
    "# âœ… Add batch dimension\n",
    "x2_batched = x2.unsqueeze(0).float()  # (1, T, C, H, W)\n",
    "print(f\"\\nðŸš€ x2_batched shape (ready for model): {x2_batched.shape}\")\n",
    "\n",
    "# âœ… Instantiate your model\n",
    "model_with_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x2.shape[1],  # C\n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",\n",
    "    use_doy=True  # IMPORTANT: model expects to use DOY, will auto-create\n",
    ")\n",
    "\n",
    "# âœ… Forward pass without giving DOY (will create dummy DOY internally)\n",
    "print(\"\\n>>> Running forward on model with use_doy=True but doy=None:\")\n",
    "out_auto_doy = model_with_doy.forward(x2_batched, None)\n",
    "print(f\"âœ… Output shape (auto dummy DOY created inside forward): {out_auto_doy.shape}\")\n",
    "\n",
    "# âœ… Extra: you can also force `use_doy=False` to see different behavior\n",
    "model_no_doy = SMPTempModel(\n",
    "    encoder_name=\"resnet18\",\n",
    "    n_channels=x2.shape[1],\n",
    "    flatten_temporal_dimension=False,\n",
    "    pos_class_weight=1.0,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    loss_function=\"Dice\",\n",
    "    use_doy=False  # model does NOT use DOY at all\n",
    ")\n",
    "\n",
    "print(\"\\n>>> Running forward on model with use_doy=False (also creates dummy internally):\")\n",
    "out_forced_no_doy = model_no_doy.forward(x2_batched, None)\n",
    "print(f\"âœ… Output shape (use_doy=False so dummy DOY used anyway): {out_forced_no_doy.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3ed420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Encoder-only state_dict saved to /Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/src/models/utae_paps_models/Gallelio-weights/seco_resnet18_1m.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "ckpt_path = \"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/src/models/utae_paps_models/Gallelio-weights/seco_resnet18_1m.ckpt\"               # input .ckpt file path\n",
    "# output_full_model_path = \"seco_resnet18_full.pth\" # will contain full state_dict\n",
    "output_encoder_path = \"/Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/src/models/utae_paps_models/Gallelio-weights/seco_resnet18_1m.pth\" # will contain encoder-only weights\n",
    "\n",
    "# === LOAD CHECKPOINT ===\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "# Handle both old and raw state_dict formats\n",
    "if \"state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"state_dict\"]\n",
    "else:\n",
    "    state_dict = checkpoint  # raw dict\n",
    "\n",
    "# === SAVE FULL MODEL IN COMPATIBLE FORMAT ===\n",
    "# torch.save({\"state_dict\": state_dict}, output_full_model_path)\n",
    "# print(f\"âœ… Full model state_dict saved to {output_full_model_path}\")\n",
    "\n",
    "# === OPTIONALLY SAVE ENCODER-ONLY VERSION ===\n",
    "encoder_prefix = \"encoder.\"\n",
    "encoder_state_dict = {\n",
    "    k[len(encoder_prefix):]: v\n",
    "    for k, v in state_dict.items()\n",
    "    if k.startswith(encoder_prefix)\n",
    "}\n",
    "\n",
    "torch.save({\"state_dict\": encoder_state_dict}, output_encoder_path)\n",
    "print(f\"âœ… Encoder-only state_dict saved to {output_encoder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f346076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 keys in state_dict:\n",
      " 1: queue\n",
      " 2: queue_ptr\n",
      " 3: encoder_q.0.weight\n",
      " 4: encoder_q.1.weight\n",
      " 5: encoder_q.1.bias\n",
      " 6: encoder_q.1.running_mean\n",
      " 7: encoder_q.1.running_var\n",
      " 8: encoder_q.1.num_batches_tracked\n",
      " 9: encoder_q.4.0.conv1.weight\n",
      "10: encoder_q.4.0.bn1.weight\n",
      "11: encoder_q.4.0.bn1.bias\n",
      "12: encoder_q.4.0.bn1.running_mean\n",
      "13: encoder_q.4.0.bn1.running_var\n",
      "14: encoder_q.4.0.bn1.num_batches_tracked\n",
      "15: encoder_q.4.0.conv2.weight\n",
      "16: encoder_q.4.0.bn2.weight\n",
      "17: encoder_q.4.0.bn2.bias\n",
      "18: encoder_q.4.0.bn2.running_mean\n",
      "19: encoder_q.4.0.bn2.running_var\n",
      "20: encoder_q.4.0.bn2.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu',weights_only=False)\n",
    "\n",
    "# Get actual state_dict\n",
    "state_dict = checkpoint[\"state_dict\"] if \"state_dict\" in checkpoint else checkpoint\n",
    "\n",
    "# Check all keys (print first 20)\n",
    "print(\"First 20 keys in state_dict:\")\n",
    "for i, key in enumerate(state_dict):\n",
    "    print(f\"{i+1:2d}: {key}\")\n",
    "    if i == 19:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df654247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 120 encoder_q params\n",
      "âœ… Encoder weights saved to /Users/sameeps/Documents/Dr-Malof/WIldfire/WildfireSpreadTS/src/models/utae_paps_models/Gallelio-weights/seco_resnet18_1m.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ckpt_path = \"seco_resnet18_1m.ckpt\"\n",
    "# output_encoder_path = \"seco_resnet18_encoder.pth\"\n",
    "\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "state_dict = checkpoint[\"state_dict\"] if \"state_dict\" in checkpoint else checkpoint\n",
    "\n",
    "# Updated prefix\n",
    "prefix = \"encoder_q.\"\n",
    "encoder_state_dict = {\n",
    "    k[len(prefix):]: v\n",
    "    for k, v in state_dict.items()\n",
    "    if k.startswith(prefix)\n",
    "}\n",
    "\n",
    "print(f\"âœ… Found {len(encoder_state_dict)} encoder_q params\")\n",
    "\n",
    "# Save wrapped in {\"state_dict\": ...} to work with your load_checkpoint()\n",
    "torch.save({\"state_dict\": encoder_state_dict}, output_encoder_path)\n",
    "print(f\"âœ… Encoder weights saved to {output_encoder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5366b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildfire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
